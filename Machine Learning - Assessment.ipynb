{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Machine learning project notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student: G00219132 Susan Hudson - Module: Machine Learning & Statistics, GMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook structure\n",
    "\n",
    "The notebook is split up into the following sections which are based on the project statement requirements.\n",
    "\n",
    "* Section One - General setup and importation of necessary python libraries/packages and dataset\n",
    "* Section Two - Descriptive Statistics\n",
    "* Section Three - Inferential Statistics\n",
    "* Section Four - Predictive Statistics\n",
    "* Section Five - references and conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section One - Importing libraries and dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of python packages used in this notebook and the loading of the dataset and conversion to a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import all necessary python packages for this vnotebook\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "#Matplotlib is a Python plotting library and Pyplot is a matplotlib module which provides a MATLAB type interface.\n",
    "plt.rcParams['figure.figsize'] = [10, 6]  #sets figure sizes for plots\n",
    "%matplotlib inline  \n",
    "#command abovr ensures plots display correctly in the notebook\n",
    "import seaborn as sns  #Seaborn is a Python package used for plotting data.\n",
    "import pandas as pd  #Pandas is a Python package for use with data frames.\n",
    "import scipy.stats as ss #statistical functions package\n",
    "import numpy as np #NumPy is a Python package for mathematical computing\n",
    "import sklearn.datasets #dataset location\n",
    "import keras as kr #deep learning library - used for predictive neural networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset is imported and converted to a pandas dataframe\n",
    "sklearn.datasets.load_boston\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['MEDV'] = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Section Two - Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Statistics looks at sunmary statistics for the population sample [1], to get a 'feel' for the data. I have chosen both visual and quamtitative analysis methods. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data set shape and print first five rows \n",
    "print(boston.data.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a table of the summary statistics for all columns in the dataset\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below outines the characteristcs of the dataset and explains what each variable represents in the dataset.\n",
    "# Note - this dataset is from the 1970s and some attributes are a reflection of those times, for the purpose of the project\n",
    "# I imported the dataset as a whole but will not be considering some of the variables when doing evaluations of data subsets!\n",
    "\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of Median Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below I am looking at the distribution of the target variable, MEDV\n",
    "\n",
    "sns.distplot(df[\"MEDV\"], bins=40)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot of Median Value shows a mainly normal distribution. It looks like there is some sort of price capping /banding as there seem to be a disproportionate number of properties with median value 50. \n",
    "The box plot of MEDV below appears to back up this opinion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a box plot of MEDV to look at the shape\n",
    "sns.boxplot(df.MEDV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation\n",
    "I then looked at whether there was much, or any correlation between the individual dataset variables and in particular whether any strong correlations existed between target variable MEDV and other variables. \n",
    "\n",
    "I did both a correlarion heatmap for a visual display and a correlaion table. \n",
    "\n",
    "Correlation is a statistical measure of the degree to which changes to the value of one variable predict change to the value of another. A coefficient close to  1 would indicate that the two change in the same direction, e.g as one increases the other increases, as one decreases the other decreases. A value close to -1 indicates a strong negative correlation, e.g as one variable increases the other decreases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a correlation heatmap of the dataset\n",
    "\n",
    "correlation_heatmap = df.corr().round(2)\n",
    "fig, ax = plt.subplots(figsize=(10,6))   \n",
    "sns.heatmap(correlation_heatmap, annot=True,linewidths= 1, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation table for the dataset\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the correlation heatmap/table the strongest correlations with MEDV are a positive correlation with RM, average number of rooms per dwelling and a negative correlation with LSTAT % lower status of the population.\n",
    "This would make sense as one would imagine that house prices are higher when they are larger and also that they would be lower in poorer areas. This is supported by the negative correlation between LSTAT and RM, the higher the % of 'lower status' the lower the number of rooms. There is also a negative correlation with PTRATIO pupil-teacher ratio by town. It appears that the higher the PTRATIO the lower the MEDV This could imply that areas of lower socio economic status would have higher PTRATIO, it could be attributed to funding or even orevalence of orivate schools in more affluent areas. The posive correlation between LSTAT and PTRATIO could support this observation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution plots\n",
    "Below are distribution plots for each variable. Some appear skewed, CRIM, ZN, AGE for example. RM and MEDV are normally distributed.  As CHAS is categorical the distribution shows merely the counts for each value, 1 or 0, worth noting that there are a far greated number at 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=10, figsize=(15,10), grid=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section Three - Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inferential statistics looks at the sample and infers trends about the larger population from which the sample was drawn. Where populations are large it would be impossible to get data for the entire population so inferences are made based on the statistical sample. The project brief was to analyse whether there was a sigificant difference in median house prices between houses along the Charles river and those that aren't. \n",
    "\n",
    "To do this I decided to do a two sample t test and create two subsets to do a t test to see whether the mean of median values is the same for houses bordering the river and houses not near the river. The null hypothesis I am testing being that there is no difference in the average median value of houses bordering the river and houses not near the river.\n",
    "\n",
    "The alternative hypothesis being that there is a difference in median values of houses bordering the river and houses not near the river."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two subsets to do a t test dfnear, houses bordering the river, dffar houses away from the river\n",
    "\n",
    "# houses bordering the river\n",
    "dfnear =  df[(df['CHAS'] == 1.0)]\n",
    "dfnear.reset_index(inplace= True)\n",
    "#print ( dfnear)\n",
    "\n",
    "#houses bordering the river with values of 50k removed\n",
    "dfnear2 =  df[(df['CHAS'] == 1.0)]\n",
    "dfnearno_out = dfnear2[(dfnear2['MEDV']<40)]\n",
    "#print (dfnearno_out)\n",
    "\n",
    "#houses away from the river\n",
    "dffar =  df[(df['CHAS'] == 0.0)]\n",
    "dffar.reset_index(inplace= True)\n",
    "print(dffar)\n",
    "\n",
    "# t test houses near and houses away from river\n",
    "from scipy.stats import ttest_ind\n",
    "n =dfnear['MEDV']\n",
    "f =dffar['MEDV']\n",
    "result = ss.ttest_ind(n,f)\n",
    "print('t test result for CHAS:  ', result)\n",
    "# result obtained causes me to reject the hypothesis\n",
    "n_noout = dfnearno_out['MEDV']\n",
    "\n",
    "# t test houses near the river excluding values of 50 and houses away from river\n",
    "from scipy.stats import ttest_ind\n",
    "dfnearno_out['MEDV']\n",
    "f =dffar['MEDV']\n",
    "result = ss.ttest_ind(n_noout,f)\n",
    "print('t test result for CHAS, no 50k values included:  ', result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial result obtained causes me to reject the null hypothesis and conclude that the mean of median value for houses along the river is not equal to the mean of median values of houses away from the river. However, below I took a further look at the two subsets of data for CHAS. Looking at the distributions I am not convinced that the t test is of any value as I don't feel that the data follows the required conitions for being approximately normal [2]. The sample away from the river is OK but those near the river are a appear to have a distribution with outliers, this appears to be mainly the the 'capped' 50k values. \n",
    "\n",
    "Having reviewed the plots I repeated the t test, this time removing values of 50k. The resulting p value of 0.51 would mean that 1 cannot conclude that a significant difference exists. \n",
    "However I am sticking with the original rejection on the basis that in this instance removal of outliers is not correct as the outliers are capped values so in all liklihood are 50 and above and in the sample size represent 20% of the total sample so are not insignificant. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn distribution plots \n",
    "\n",
    "sns.distplot(dfnear[\"MEDV\"], bins=10).set_title (\"MEDV Distribution where houses near river\")\n",
    "plt.show()\n",
    "sns.distplot(dffar[\"MEDV\"], bins=10).set_title (\"MEDV Distribution where houses away fron river\")\n",
    "plt.show()\n",
    "sns.distplot(dfnearno_out[\"MEDV\"], bins=10).set_title (\"MEDV Distribution where houses near river no 50k values\")\n",
    "plt.show()\n",
    "\n",
    "#box plot with stripplot overlaid to show data points\n",
    "df4 = pd.DataFrame(data = dfnear, columns = [ 'MEDV'] )\n",
    "sns.boxplot(x=\"variable\", y=\"value\", data= pd.melt(df4), palette=\"bright\").set_title(\"House values near River \")\n",
    "sns.stripplot(x=\"variable\", y=\"value\", data= pd.melt(df4), palette=\"dark\").set_title(\"House values near River \")\n",
    "plt.ylabel('Median house cost')\n",
    "plt.xlabel('')\n",
    "plt.show()\n",
    "\n",
    "#box plot with stripplot overlaid to show data points\n",
    "df5 = pd.DataFrame(data = dffar, columns = [ 'MEDV'] )\n",
    "sns.stripplot (x=\"variable\", y=\"value\", data= pd.melt(df5), palette=\"dark\").set_title(\"House values away from River \")\n",
    "sns.boxplot(x=\"variable\", y=\"value\", data= pd.melt(df5), palette=\"bright\").set_title(\"House values away from River \")\n",
    "plt.ylabel('Median house cost')\n",
    "plt.xlabel('')\n",
    "plt.show()\n",
    "\n",
    "#box plot with stripplot overlaid to show data points\n",
    "df6 = pd.DataFrame(data = dfnearno_out, columns = [ 'MEDV'] )\n",
    "sns.boxplot(x=\"variable\", y=\"value\", data= pd.melt(df6), palette=\"bright\").set_title(\"House values near River no 50k \")\n",
    "sns.stripplot(x=\"variable\", y=\"value\", data= pd.melt(df6), palette=\"dark\").set_title(\"House values near River no 50k \")\n",
    "plt.ylabel('Median house cost')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section four - predictive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The brief for this section of the project was to use Keras to build a neural network that could predict the median house price (MEDV) based on the other values in the dataset. There were no other restrictions and I decided to take the following approach. \n",
    "* build a neural network and train on all variables, \n",
    "* look at some pre processing of data and again train on all variables.\n",
    "* Reduce the number of inputs and repeat the above approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select all variables as inputs and MEDV as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,0:13]\n",
    "y = df.iloc[:,13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build neural network model\n",
    "the neural network I built is a sequential model where layers were added one at a time. \n",
    "I experimented wirh different layer densities, activitation functions, initializers and optimizers in the model itself and with different numbers of epochs and batch size when training the model. after much trial and error I settled on the model below, two layers of 64 neurons wrelu activation and an output layer of 1 neuron and linear activation.\n",
    "\n",
    "This gave the lowest loss values although los values are fluctuating. I increased the batch size to the full dataset when training and could see less fluctations so think they are a result of the number of variables and the differences across variables when batch sizes are relatively small. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "m = models.Sequential()\n",
    "m.add(layers.Dense(64, activation='relu', input_dim =13))\n",
    "m.add(layers.Dense(64, activation='relu'))\n",
    "#m.add(Dense(1,kernel_initializer='normal',activation='linear',use_bias=False))\n",
    "m.add(layers.Dense(1,kernel_initializer='normal',activation='linear',use_bias=False))\n",
    "m.compile(loss='mse', optimizer='adam',metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-676b45d80fcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# split the dataset into test(20%) and train (80%) values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# split the dataset into test(20%) and train (80%) values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "m.fit(x_train, y_train, epochs=1000, batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m.metrics_names)\n",
    "m.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above trained model I will use the test input variables to predict output variable MEDV for the test portion o f the split dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p = m.predict(x_test)\n",
    "#m.summary()\n",
    "\n",
    "predictval =  np.around(m.predict(x_test).T,2)\n",
    "print(predictval)\n",
    "original = (y_test.as_matrix().astype(np.float32))\n",
    "print(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking at the predictions versus the actual and remembering that the figures represent thousands on the surface some predictions appear reasonable - 13 input variables and predictions within 5%. however there are some that are way off and no consistency in prediction versus acual. The next step was to do some pre processing and see whether the model output improved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reducing input variables \n",
    "I repeated the above using less input variables and was surprised that performance was worse in terms of ability to be trained, predict. loss evaluation was much higher (53 vs 12) for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now going to repeat the above using the four inputs of most interest\n",
    "Y=df['MEDV']\n",
    "#print(Y)\n",
    "Xfour =df[['RM', 'LSTAT','PTRATIO' ]]\n",
    "#print(Xfour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after an initial run I tweaked the neural network to try to reduce loss\n",
    "m = models.Sequential()\n",
    "m.add(layers.Dense(39, activation='relu', input_dim =3))\n",
    "m.add(layers.Dense(39, activation='relu'))\n",
    "m.add(Dense(1,kernel_initializer='normal',activation='linear',use_bias=False))\n",
    "\n",
    "m.compile(loss='mse', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(Xfour, Y, test_size=0.2)\n",
    "m.fit(x_train, y_train, epochs=1000, batch_size=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m.metrics_names)\n",
    "m.evaluate(Xfour, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.predict(x_test)\n",
    "#m.summary()\n",
    "\n",
    "predictval =  np.around(m.predict(x_test).T,2)\n",
    "print(predictval)\n",
    "output = (y_test.as_matrix().astype(np.float32))\n",
    "print(output)\n",
    "round(np.sqrt(np.sum((m.predict(x_test).T -output)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing of Data for Keras\n",
    "I will now investigate whether pre processing the data (using all 13 inputs) makes any significant difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       " 0   -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       " 1   -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       " 2   -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       " 3   -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       " 4   -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       " ..        ...       ...       ...       ...       ...       ...       ...   \n",
       " 501 -0.413229 -0.487722  0.115738 -0.272599  0.158124  0.439316  0.018673   \n",
       " 502 -0.415249 -0.487722  0.115738 -0.272599  0.158124 -0.234548  0.288933   \n",
       " 503 -0.413447 -0.487722  0.115738 -0.272599  0.158124  0.984960  0.797449   \n",
       " 504 -0.407764 -0.487722  0.115738 -0.272599  0.158124  0.725672  0.736996   \n",
       " 505 -0.415000 -0.487722  0.115738 -0.272599  0.158124 -0.362767  0.434732   \n",
       " \n",
       "           DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       " 0    0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
       " 1    0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
       " 2    0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
       " 3    1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
       " 4    1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  \n",
       " ..        ...       ...       ...       ...       ...       ...  \n",
       " 501 -0.625796 -0.982843 -0.803212  1.176466  0.387217 -0.418147  \n",
       " 502 -0.716639 -0.982843 -0.803212  1.176466  0.441052 -0.500850  \n",
       " 503 -0.773684 -0.982843 -0.803212  1.176466  0.441052 -0.983048  \n",
       " 504 -0.668437 -0.982843 -0.803212  1.176466  0.403225 -0.865302  \n",
       " 505 -0.613246 -0.982843 -0.803212  1.176466  0.441052 -0.669058  \n",
       " \n",
       " [506 rows x 13 columns],             0\n",
       " 0    0.159686\n",
       " 1   -0.101524\n",
       " 2    1.324247\n",
       " 3    1.182758\n",
       " 4    1.487503\n",
       " ..        ...\n",
       " 501 -0.014454\n",
       " 502 -0.210362\n",
       " 503  0.148802\n",
       " 504 -0.057989\n",
       " 505 -1.157248\n",
       " \n",
       " [506 rows x 1 columns])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing of all dataset[]\n",
    "# scaling \n",
    "import sklearn.preprocessing as pre\n",
    "xscale = pd.DataFrame(pre.scale(x), columns = x.columns)\n",
    "xscale\n",
    "yscale = pd.DataFrame(pre.scale(y))\n",
    "xscale, yscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fitting and transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.61352356e+00, 1.13636364e+01, 1.11367787e+01, 6.91699605e-02,\n",
       "        5.54695059e-01, 6.28463439e+00, 6.85749012e+01, 3.79504269e+00,\n",
       "        9.54940711e+00, 4.08237154e+02, 1.84555336e+01, 3.56674032e+02,\n",
       "        1.26530632e+01]), CRIM         8.601545\n",
       " ZN          23.322453\n",
       " INDUS        6.860353\n",
       " CHAS         0.253994\n",
       " NOX          0.115878\n",
       " RM           0.702617\n",
       " AGE         28.148861\n",
       " DIS          2.105710\n",
       " RAD          8.707259\n",
       " TAX        168.537116\n",
       " PTRATIO      2.164946\n",
       " B           91.294864\n",
       " LSTAT        7.141062\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=pre.StandardScaler()\n",
    "scaler.fit(x)\n",
    "x\n",
    "scaler.mean_ , x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xscale = pd.DataFrame(scaler.transform(x), columns = x.columns)\n",
    "xscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "m = models.Sequential()\n",
    "m.add(layers.Dense(64, activation='relu', input_dim =13))\n",
    "m.add(layers.Dense(64, activation='relu', input_dim =13))\n",
    "m.add(Dense(1,kernel_initializer='normal',activation='linear',use_bias=False))\n",
    "\n",
    "m.compile(loss='mse', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(xscale, y, test_size = 0.2)\n",
    "m.fit(X_train, Y_train, epochs=1000, batch_size=22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n",
      "506/506 [==============================] - 0s 585us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.685029376636852, 0.09288537502288818]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(m.metrics_names)\n",
    "m.evaluate(xscale, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.47418212890625, 0.019607843831181526]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate prediction loss\n",
    "m.predict(X_test_scaled).round().T\n",
    "Y_test.as_matrix().astype(np.float32)\n",
    "m.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### whitening data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>CRIM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.625505</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.455621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ZN</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.412995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.603800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CHAS</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.053929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NOX</td>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.590879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RM</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.613808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AGE</td>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.602339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DIS</td>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.496996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RAD</td>\n",
       "      <td>0.625505</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>0.488676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TAX</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>0.543993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>0.374044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.366087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LSTAT</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "CRIM     1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
       "ZN      -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
       "INDUS    0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
       "CHAS    -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
       "NOX      0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
       "RM      -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
       "AGE      0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
       "DIS     -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
       "RAD      0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
       "TAX      0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
       "PTRATIO  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
       "B       -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
       "LSTAT    0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
       "\n",
       "              DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "CRIM    -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621  \n",
       "ZN       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  \n",
       "INDUS   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800  \n",
       "CHAS    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  \n",
       "NOX     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879  \n",
       "RM       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  \n",
       "AGE     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339  \n",
       "DIS      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  \n",
       "RAD     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676  \n",
       "TAX     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993  \n",
       "PTRATIO -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044  \n",
       "B        0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  \n",
       "LSTAT   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xwhite_train, xwhite_test, ywhite_train, ywhite_test = train_test_split(x, y, test_size = 0.2)\n",
    "x.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.554536</td>\n",
       "      <td>0.339165</td>\n",
       "      <td>-0.436310</td>\n",
       "      <td>-0.522168</td>\n",
       "      <td>-0.048450</td>\n",
       "      <td>-0.887684</td>\n",
       "      <td>-0.694780</td>\n",
       "      <td>-0.335010</td>\n",
       "      <td>0.536407</td>\n",
       "      <td>-0.038723</td>\n",
       "      <td>-0.041052</td>\n",
       "      <td>3.785653</td>\n",
       "      <td>-0.723778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.730177</td>\n",
       "      <td>-0.062618</td>\n",
       "      <td>-0.067972</td>\n",
       "      <td>-1.115359</td>\n",
       "      <td>0.147648</td>\n",
       "      <td>-0.356882</td>\n",
       "      <td>-0.076542</td>\n",
       "      <td>-0.151480</td>\n",
       "      <td>-0.728876</td>\n",
       "      <td>0.173575</td>\n",
       "      <td>0.682770</td>\n",
       "      <td>-0.172845</td>\n",
       "      <td>0.446336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.664179</td>\n",
       "      <td>-1.516959</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.025371</td>\n",
       "      <td>-1.923739</td>\n",
       "      <td>1.297532</td>\n",
       "      <td>3.195349</td>\n",
       "      <td>3.645164</td>\n",
       "      <td>-0.681283</td>\n",
       "      <td>-0.194521</td>\n",
       "      <td>-0.230173</td>\n",
       "      <td>0.037578</td>\n",
       "      <td>-1.277022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.817228</td>\n",
       "      <td>-0.005165</td>\n",
       "      <td>-0.345135</td>\n",
       "      <td>1.323194</td>\n",
       "      <td>-0.057734</td>\n",
       "      <td>0.371731</td>\n",
       "      <td>1.319661</td>\n",
       "      <td>-1.663135</td>\n",
       "      <td>-0.730084</td>\n",
       "      <td>-0.102496</td>\n",
       "      <td>0.467361</td>\n",
       "      <td>-0.645813</td>\n",
       "      <td>-1.621954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.418404</td>\n",
       "      <td>-1.383860</td>\n",
       "      <td>-0.286932</td>\n",
       "      <td>0.307957</td>\n",
       "      <td>-0.067292</td>\n",
       "      <td>-0.259872</td>\n",
       "      <td>-0.544750</td>\n",
       "      <td>-0.677901</td>\n",
       "      <td>-0.065441</td>\n",
       "      <td>0.315039</td>\n",
       "      <td>-0.290046</td>\n",
       "      <td>-0.359325</td>\n",
       "      <td>0.692215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>-0.630367</td>\n",
       "      <td>0.044950</td>\n",
       "      <td>1.217556</td>\n",
       "      <td>-2.741395</td>\n",
       "      <td>0.196047</td>\n",
       "      <td>0.533153</td>\n",
       "      <td>1.069602</td>\n",
       "      <td>-0.408614</td>\n",
       "      <td>-0.164883</td>\n",
       "      <td>-0.010950</td>\n",
       "      <td>-0.609372</td>\n",
       "      <td>-0.114435</td>\n",
       "      <td>-0.426412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.439478</td>\n",
       "      <td>-1.177965</td>\n",
       "      <td>-0.172456</td>\n",
       "      <td>0.184495</td>\n",
       "      <td>-1.022794</td>\n",
       "      <td>-1.417373</td>\n",
       "      <td>-0.131307</td>\n",
       "      <td>-0.931688</td>\n",
       "      <td>-0.326040</td>\n",
       "      <td>0.196653</td>\n",
       "      <td>2.414885</td>\n",
       "      <td>-0.483383</td>\n",
       "      <td>1.759812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>401</td>\n",
       "      <td>-0.787380</td>\n",
       "      <td>-0.024167</td>\n",
       "      <td>-0.441772</td>\n",
       "      <td>-0.630024</td>\n",
       "      <td>0.011187</td>\n",
       "      <td>-1.032520</td>\n",
       "      <td>-0.535877</td>\n",
       "      <td>1.303050</td>\n",
       "      <td>0.060603</td>\n",
       "      <td>-0.859208</td>\n",
       "      <td>-1.391527</td>\n",
       "      <td>-0.170314</td>\n",
       "      <td>-0.673719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>402</td>\n",
       "      <td>1.979419</td>\n",
       "      <td>3.352224</td>\n",
       "      <td>-0.058084</td>\n",
       "      <td>0.360270</td>\n",
       "      <td>0.616302</td>\n",
       "      <td>1.891122</td>\n",
       "      <td>-1.389529</td>\n",
       "      <td>0.101597</td>\n",
       "      <td>0.172518</td>\n",
       "      <td>-0.317915</td>\n",
       "      <td>1.136648</td>\n",
       "      <td>0.078508</td>\n",
       "      <td>-2.281301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>403</td>\n",
       "      <td>-0.057188</td>\n",
       "      <td>-0.444510</td>\n",
       "      <td>-0.924346</td>\n",
       "      <td>0.323082</td>\n",
       "      <td>-0.396484</td>\n",
       "      <td>-0.016343</td>\n",
       "      <td>1.968650</td>\n",
       "      <td>0.021937</td>\n",
       "      <td>1.739868</td>\n",
       "      <td>0.928546</td>\n",
       "      <td>1.005435</td>\n",
       "      <td>-0.787559</td>\n",
       "      <td>-1.101238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0   -0.554536  0.339165 -0.436310 -0.522168 -0.048450 -0.887684 -0.694780   \n",
       "1   -0.730177 -0.062618 -0.067972 -1.115359  0.147648 -0.356882 -0.076542   \n",
       "2    1.664179 -1.516959  0.000787  0.025371 -1.923739  1.297532  3.195349   \n",
       "3   -0.817228 -0.005165 -0.345135  1.323194 -0.057734  0.371731  1.319661   \n",
       "4    1.418404 -1.383860 -0.286932  0.307957 -0.067292 -0.259872 -0.544750   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "399 -0.630367  0.044950  1.217556 -2.741395  0.196047  0.533153  1.069602   \n",
       "400  1.439478 -1.177965 -0.172456  0.184495 -1.022794 -1.417373 -0.131307   \n",
       "401 -0.787380 -0.024167 -0.441772 -0.630024  0.011187 -1.032520 -0.535877   \n",
       "402  1.979419  3.352224 -0.058084  0.360270  0.616302  1.891122 -1.389529   \n",
       "403 -0.057188 -0.444510 -0.924346  0.323082 -0.396484 -0.016343  1.968650   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0   -0.335010  0.536407 -0.038723 -0.041052  3.785653 -0.723778  \n",
       "1   -0.151480 -0.728876  0.173575  0.682770 -0.172845  0.446336  \n",
       "2    3.645164 -0.681283 -0.194521 -0.230173  0.037578 -1.277022  \n",
       "3   -1.663135 -0.730084 -0.102496  0.467361 -0.645813 -1.621954  \n",
       "4   -0.677901 -0.065441  0.315039 -0.290046 -0.359325  0.692215  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "399 -0.408614 -0.164883 -0.010950 -0.609372 -0.114435 -0.426412  \n",
       "400 -0.931688 -0.326040  0.196653  2.414885 -0.483383  1.759812  \n",
       "401  1.303050  0.060603 -0.859208 -1.391527 -0.170314 -0.673719  \n",
       "402  0.101597  0.172518 -0.317915  1.136648  0.078508 -2.281301  \n",
       "403  0.021937  1.739868  0.928546  1.005435 -0.787559 -1.101238  \n",
       "\n",
       "[404 rows x 13 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.decomposition as dec\n",
    "pca = dec.PCA(n_components = 13, whiten = True)\n",
    "pca.fit(xwhite_train)\n",
    "x_whitenedtrain = pd.DataFrame(pca.transform(xwhite_train), columns=x.columns)\n",
    "x_whitenedtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         CRIM   ZN  INDUS  CHAS  NOX   RM  AGE  DIS  RAD  TAX  PTRATIO    B  \\\n",
       " CRIM      1.0  0.0   -0.0   0.0  0.0  0.0  0.0 -0.0  0.0  0.0     -0.0  0.0   \n",
       " ZN        0.0  1.0    0.0   0.0 -0.0  0.0 -0.0 -0.0  0.0 -0.0      0.0 -0.0   \n",
       " INDUS    -0.0  0.0    1.0  -0.0 -0.0 -0.0  0.0 -0.0 -0.0  0.0      0.0  0.0   \n",
       " CHAS      0.0  0.0   -0.0   1.0  0.0 -0.0  0.0  0.0 -0.0  0.0      0.0 -0.0   \n",
       " NOX       0.0 -0.0   -0.0   0.0  1.0  0.0  0.0  0.0 -0.0 -0.0      0.0  0.0   \n",
       " RM        0.0  0.0   -0.0  -0.0  0.0  1.0  0.0  0.0 -0.0  0.0      0.0 -0.0   \n",
       " AGE       0.0 -0.0    0.0   0.0  0.0  0.0  1.0 -0.0 -0.0  0.0     -0.0 -0.0   \n",
       " DIS      -0.0 -0.0   -0.0   0.0  0.0  0.0 -0.0  1.0 -0.0 -0.0     -0.0 -0.0   \n",
       " RAD       0.0  0.0   -0.0  -0.0 -0.0 -0.0 -0.0 -0.0  1.0  0.0      0.0 -0.0   \n",
       " TAX       0.0 -0.0    0.0   0.0 -0.0  0.0  0.0 -0.0  0.0  1.0      0.0 -0.0   \n",
       " PTRATIO  -0.0  0.0    0.0   0.0  0.0  0.0 -0.0 -0.0  0.0  0.0      1.0  0.0   \n",
       " B         0.0 -0.0    0.0  -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0      0.0  1.0   \n",
       " LSTAT    -0.0  0.0    0.0   0.0  0.0 -0.0 -0.0 -0.0  0.0 -0.0      0.0 -0.0   \n",
       " \n",
       "          LSTAT  \n",
       " CRIM      -0.0  \n",
       " ZN         0.0  \n",
       " INDUS      0.0  \n",
       " CHAS       0.0  \n",
       " NOX        0.0  \n",
       " RM        -0.0  \n",
       " AGE       -0.0  \n",
       " DIS       -0.0  \n",
       " RAD        0.0  \n",
       " TAX       -0.0  \n",
       " PTRATIO    0.0  \n",
       " B         -0.0  \n",
       " LSTAT      1.0  , CRIM      -0.0\n",
       " ZN        -0.0\n",
       " INDUS     -0.0\n",
       " CHAS       0.0\n",
       " NOX        0.0\n",
       " RM         0.0\n",
       " AGE        0.0\n",
       " DIS       -0.0\n",
       " RAD       -0.0\n",
       " TAX       -0.0\n",
       " PTRATIO   -0.0\n",
       " B          0.0\n",
       " LSTAT     -0.0\n",
       " dtype: float64, CRIM       1.0\n",
       " ZN         1.0\n",
       " INDUS      1.0\n",
       " CHAS       1.0\n",
       " NOX        1.0\n",
       " RM         1.0\n",
       " AGE        1.0\n",
       " DIS        1.0\n",
       " RAD        1.0\n",
       " TAX        1.0\n",
       " PTRATIO    1.0\n",
       " B          1.0\n",
       " LSTAT      1.0\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_whitenedtrain.corr().round(),x_whitenedtrain.mean().round(),x_whitenedtrain.std().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build neural network model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "Y=df['MEDV']\n",
    "print(Y)\n",
    "X =df[['ZN','RM', 'LSTAT','PTRATIO' ]]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "m = models.Sequential()\n",
    "m.add(layers.Dense(64, activation='relu', input_dim =13))\n",
    "m.add(layers.Dense(64, activation='relu', input_dim =13))\n",
    "m.add(Dense(1,kernel_initializer='normal',activation='linear',use_bias=False))\n",
    "\n",
    "m.compile(loss='mse', optimizer='adam',metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "404/404 [==============================] - 1s 4ms/step - loss: 573.5651 - accuracy: 0.0000e+00: 0s - loss: 609.8234 - accuracy: 0.0000e+\n",
      "Epoch 2/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 531.4849 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 451.5767 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "404/404 [==============================] - 0s 928us/step - loss: 328.0770 - accuracy: 0.0025\n",
      "Epoch 5/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 192.2675 - accuracy: 0.0000e+00: 0s - loss: 210.9964 - accuracy: \n",
      "Epoch 6/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 117.2359 - accuracy: 0.0099\n",
      "Epoch 7/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 97.5745 - accuracy: 0.0050\n",
      "Epoch 8/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 91.8224 - accuracy: 0.0050\n",
      "Epoch 9/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 88.7915 - accuracy: 0.0074\n",
      "Epoch 10/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 86.9437 - accuracy: 0.0050\n",
      "Epoch 11/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 85.7445 - accuracy: 0.0050\n",
      "Epoch 12/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 84.6886 - accuracy: 0.0050\n",
      "Epoch 13/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 84.1213 - accuracy: 0.0025\n",
      "Epoch 14/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 83.4001 - accuracy: 0.0074\n",
      "Epoch 15/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 82.5299 - accuracy: 0.0074\n",
      "Epoch 16/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 81.8097 - accuracy: 0.0074\n",
      "Epoch 17/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 81.2387 - accuracy: 0.0050\n",
      "Epoch 18/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 80.8307 - accuracy: 0.0074\n",
      "Epoch 19/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 80.1615 - accuracy: 0.0050 ETA: 0s - loss: 80.5607 - accuracy: 0.005\n",
      "Epoch 20/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 79.6449 - accuracy: 0.0050\n",
      "Epoch 21/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 79.2650 - accuracy: 0.0050\n",
      "Epoch 22/100\n",
      "404/404 [==============================] - 0s 847us/step - loss: 78.7971 - accuracy: 0.0050\n",
      "Epoch 23/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 78.4387 - accuracy: 0.0050\n",
      "Epoch 24/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 77.9993 - accuracy: 0.0050\n",
      "Epoch 25/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 77.7067 - accuracy: 0.0050\n",
      "Epoch 26/100\n",
      "404/404 [==============================] - 0s 718us/step - loss: 77.6956 - accuracy: 0.0050\n",
      "Epoch 27/100\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 77.0191 - accuracy: 0.0025\n",
      "Epoch 28/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 76.8252 - accuracy: 0.0074\n",
      "Epoch 29/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 76.8012 - accuracy: 0.0074\n",
      "Epoch 30/100\n",
      "404/404 [==============================] - ETA: 0s - loss: 74.9632 - accuracy: 0.003 - 1s 2ms/step - loss: 76.5260 - accuracy: 0.0099\n",
      "Epoch 31/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 76.0883 - accuracy: 0.0074\n",
      "Epoch 32/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 75.8071 - accuracy: 0.0074- ETA: 0s - loss: 52.5743 - accuracy: 0.009\n",
      "Epoch 33/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 75.5390 - accuracy: 0.0099\n",
      "Epoch 34/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 75.3599 - accuracy: 0.0050\n",
      "Epoch 35/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 75.0992 - accuracy: 0.0074\n",
      "Epoch 36/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 75.0204 - accuracy: 0.0050\n",
      "Epoch 37/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 74.6438 - accuracy: 0.0074\n",
      "Epoch 38/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 74.5275 - accuracy: 0.0074\n",
      "Epoch 39/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 74.1694 - accuracy: 0.0074\n",
      "Epoch 40/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 74.2396 - accuracy: 0.0050\n",
      "Epoch 41/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 73.9413 - accuracy: 0.0025\n",
      "Epoch 42/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 73.7054 - accuracy: 0.0099\n",
      "Epoch 43/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 73.4511 - accuracy: 0.0099\n",
      "Epoch 44/100\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 73.3837 - accuracy: 0.0099\n",
      "Epoch 45/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 73.4153 - accuracy: 0.0074\n",
      "Epoch 46/100\n",
      "404/404 [==============================] - 0s 812us/step - loss: 72.9130 - accuracy: 0.0124\n",
      "Epoch 47/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 72.8779 - accuracy: 0.0074\n",
      "Epoch 48/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 73.4171 - accuracy: 0.0124A: 1s - loss: 62.1158 - accuracy: \n",
      "Epoch 49/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 72.9783 - accuracy: 0.0124\n",
      "Epoch 50/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 72.6460 - accuracy: 0.0074\n",
      "Epoch 51/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 72.0280 - accuracy: 0.0099\n",
      "Epoch 52/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 71.9785 - accuracy: 0.0099\n",
      "Epoch 53/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 71.7750 - accuracy: 0.0099\n",
      "Epoch 54/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 71.5237 - accuracy: 0.0050\n",
      "Epoch 55/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 71.4655 - accuracy: 0.0074\n",
      "Epoch 56/100\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 71.1616 - accuracy: 0.0099\n",
      "Epoch 57/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 71.0838 - accuracy: 0.0074\n",
      "Epoch 58/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 70.8738 - accuracy: 0.0099\n",
      "Epoch 59/100\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 70.8044 - accuracy: 0.0099\n",
      "Epoch 60/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 70.8542 - accuracy: 0.0099\n",
      "Epoch 61/100\n",
      "404/404 [==============================] - 0s 931us/step - loss: 70.0775 - accuracy: 0.0074ETA: 0s - loss: 68.5119 - accuracy: 0.0000e+0\n",
      "Epoch 62/100\n",
      "404/404 [==============================] - 0s 876us/step - loss: 70.6400 - accuracy: 0.0099\n",
      "Epoch 63/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 69.8030 - accuracy: 0.0074\n",
      "Epoch 64/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 69.8764 - accuracy: 0.0050\n",
      "Epoch 65/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 69.3069 - accuracy: 0.0099\n",
      "Epoch 66/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 69.8103 - accuracy: 0.0099\n",
      "Epoch 67/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 69.1920 - accuracy: 0.0124\n",
      "Epoch 68/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 68.9270 - accuracy: 0.0099\n",
      "Epoch 69/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 68.9547 - accuracy: 0.0074\n",
      "Epoch 70/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 69.0669 - accuracy: 0.0074\n",
      "Epoch 71/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 68.4360 - accuracy: 0.0074\n",
      "Epoch 72/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 68.8194 - accuracy: 0.0099\n",
      "Epoch 73/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 68.1844 - accuracy: 0.0099\n",
      "Epoch 74/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 67.6833 - accuracy: 0.0050\n",
      "Epoch 75/100\n",
      "404/404 [==============================] - 0s 733us/step - loss: 67.8435 - accuracy: 0.0099\n",
      "Epoch 76/100\n",
      "404/404 [==============================] - 0s 849us/step - loss: 67.8395 - accuracy: 0.0099\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 1s 1ms/step - loss: 67.0707 - accuracy: 0.0099\n",
      "Epoch 78/100\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 67.2368 - accuracy: 0.0099\n",
      "Epoch 79/100\n",
      "404/404 [==============================] - 0s 993us/step - loss: 66.7782 - accuracy: 0.0074\n",
      "Epoch 80/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 66.6255 - accuracy: 0.0050\n",
      "Epoch 81/100\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 66.4258 - accuracy: 0.0074\n",
      "Epoch 82/100\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 66.5164 - accuracy: 0.0099\n",
      "Epoch 83/100\n",
      "404/404 [==============================] - 0s 787us/step - loss: 65.7294 - accuracy: 0.0050\n",
      "Epoch 84/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 66.0345 - accuracy: 0.0124\n",
      "Epoch 85/100\n",
      "404/404 [==============================] - 0s 683us/step - loss: 65.8202 - accuracy: 0.0050\n",
      "Epoch 86/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 65.7394 - accuracy: 0.0050\n",
      "Epoch 87/100\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 65.2241 - accuracy: 0.0025\n",
      "Epoch 88/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 64.7051 - accuracy: 0.0050\n",
      "Epoch 89/100\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 64.5851 - accuracy: 0.0074\n",
      "Epoch 90/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 64.3998 - accuracy: 0.0050- ETA: 0s - loss: 60.4034 - accuracy: \n",
      "Epoch 91/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 64.0234 - accuracy: 0.0074\n",
      "Epoch 92/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 63.9101 - accuracy: 0.0074\n",
      "Epoch 93/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 63.5559 - accuracy: 0.0074\n",
      "Epoch 94/100\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 63.1994 - accuracy: 0.0074TA: 0s - loss: 63.1091 - accuracy: 0.007\n",
      "Epoch 95/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 63.4274 - accuracy: 0.0124\n",
      "Epoch 96/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 62.8461 - accuracy: 0.0074\n",
      "Epoch 97/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 62.6702 - accuracy: 0.0074\n",
      "Epoch 98/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 62.1809 - accuracy: 0.0050\n",
      "Epoch 99/100\n",
      "404/404 [==============================] - 2s 4ms/step - loss: 62.2004 - accuracy: 0.0099A: 0s - loss: 52.4518 - accuracy: 0\n",
      "Epoch 100/100\n",
      "404/404 [==============================] - 0s 1ms/step - loss: 61.7542 - accuracy: 0.0099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x16fa97c8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train, X_test, Y_train, Y_test = train_test_split(xscale, y, test_size = 0.2)\n",
    "m.fit(x_whitenedtrain, Y_train, epochs=100, batch_size=22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xscale= X_train\n",
    "#y = m.predict()\n",
    "\n",
    "#history = m.fit(X_train,Y_train, validation_split = 0.20,epochs =150, batch_size =25)\n",
    "#history = m.fit(x_train_white,Y_train, validation_split = 0.20,epochs =150, batch_size =25)\n",
    "history = m.fit(x_train_white,Y_train, epochs =75, batch_size =25)\n",
    "\n",
    "#history = m.fit(X_train,Y_train,epochs =150, batch_size =25)\n",
    "print(history.history.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_white = scaler.transform(X_test)\n",
    "m.predict(x_test_white).round().T\n",
    "Y_test.as_matrix().astype(np.float32)\n",
    "m.evaluate(x_test_white, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.predict(X_test).T\n",
    "m.summary()\n",
    "print (m.predict(X_test).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = (Y_test)\n",
    "#print(output)\n",
    "#np.sqrt(np.sum((m.predict(X_test).T -output)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "[2] https://stattrek.com/hypothesis-test/difference-in-means.aspx\n",
    "https://blog.minitab.com/blog/understanding-statistics/what-can-you-say-when-your-p-value-is-greater-than-005\n",
    "    \n",
    "    \n",
    "Pre Processing Data\n",
    "https://keras.io/models/about-keras-models/\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "https://keras.io/\n",
    "    \n",
    "### books\n",
    "[1] Statistics: A very Short Introduction Hand, D., J 2008\n",
    "test git desktop\n",
    "Python Data Analysis - Fandango, Armando\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
